# The scrapheap challenge:
## Extracting relevant biological information, including strain-specific genomic segments, from unmapped NGS-reads.

The re-mapping and filtering proccess constitutes multiple processes, in this repository we provide the code used.
Third party software used in these analysis are;
* SOAPdenovo vx.x []
* compareads vx.x []
* samtools vx.x []
* bedtools vx.x []
* picard vx.x []

Custom wrapper and annotation scripts:
1. mappingBasedFiltering.pl
    * Map reads to the Celera-reference, Y-chromosomal BAC-contigs and contaminant-database
    * Input: forward and reverse fastqs from unmapped reads
    * Output: TripleDistilled.log (counts of filtered reads) and clustering-ready fastq

1. readClustering.pl
    * Use compareads to compare the fastqs between samples
    * Input: fastqs from mappingBasedFiltering.pl
    * Output: fastqs with reads similar between strains

1. deNovoAssembly.sh
    * Performs SOAPdenovo-based assembly
    * Input: forward and reverse fastqs from readClustering.sh
    * Output: contigs in fasta-format

1. ContigSplitter.ipynb
    * Divide contigs in strain-specific and common classes
    * Input: BLAT-psl files of all-vs-all contig-alignments
    * Output: names of strain-specific contigs

1. post-ContigSplitter_pipeline.sh
    * Perform analyses downstream of contig-splitting
    * Input: Fasta's from ContigSplitter.ipynb
    * Output: (counts of) predicted Proteins and Orthologs
